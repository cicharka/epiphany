---
- name: Setup group
  group:
    name: "{{ specification.group }}"
    system: yes

- name: Setup user
  user:
    name: "{{ specification.user }}"
    system: yes
    group: "{{ specification.group }}"
    shell: "/usr/sbin/nologin"

- name: Install Java package
  package:
    name: "{{ _packages[ansible_os_family] }}"
    state: present
  vars:
    _packages:
      Debian:
        - openjdk-8-jre-headless
      RedHat:
        - java-1.8.0-openjdk-headless
  module_defaults:
    yum: { lock_timeout: "{{ yum_lock_timeout }}" }

- name: Download and unpack Kafka's binary
  include_tasks: common/download_and_unpack_binary.yml

- name: Add Kafka's bin dir to the PATH
  copy:
    content: "export PATH=$PATH:/opt/kafka/bin"
    dest: "/etc/profile.d/kafka_path.sh"
    mode: 0755

- name: Link /opt/kafka to the right version
  file:
    path: /opt/kafka
    state: link
    src: "{{ kafka_install_dir }}"

- name: Create systemd config
  template:
    dest: /etc/systemd/system/kafka.service
    owner: root
    group: root
    mode: 0644
    src: kafka.service.j2
  notify:
    - restart kafka

- name: Reload daemon
  systemd:
    daemon-reload: yes

- name: Create data_dir
  file:
    path: "{{ specification.data_dir }}"
    state: directory
    owner: "{{ specification.user }}"
    group: "{{ specification.group }}"
    mode: 0755

- name: Remove lost+found in the datadir
  file:
    path: "{{ specification.data_dir }}/lost+found"
    state: absent

- name: Create log_dir
  file:
    path: "{{ specification.log_dir }}"
    state: directory
    owner: "{{ specification.user }}"
    group: "{{ specification.group }}"
    mode: 0755

- name: Create /etc/kafka directory
  file:
    path: /etc/kafka
    state: directory
    owner: "{{ specification.user }}"
    group: "{{ specification.group }}"

# - name: link conf_dir to /opt/kafka/config
#   file: dest=/etc/kafka owner=kafka group=kafka state=link src=/opt/kafka/config

# Setup log4j.properties
- name: Create log4j.properties
  file:
    path: "{{ specification.conf_dir }}/log4j.properties"
    owner: "{{ specification.user }}"
    group: "{{ specification.group }}"
    mode: 0644

- name: Generate certificate
  include_tasks: generate-certificates.yml
  when:
    - specification.security.ssl.enabled is defined
    - specification.security.ssl.enabled

# Setup server.properties
- name: Create server.properties
  template:
    dest: "{{ specification.conf_dir }}/server.properties"
    owner: "{{ specification.user }}"
    group: "{{ specification.group }}"
    # Was 0640
    mode: 0644
    src: server.properties.j2
  register: create_server_properties
  notify:
    - restart kafka

- name: Delete meta.properties
  become: true
  file:
    path: "{{ specification.data_dir }}/meta.properties"
    state: absent
  when: create_server_properties.changed

- name: Copy logrotate config
  template:
    dest: /etc/logrotate.d/kafka
    owner: root
    group: root
    mode: 0644
    src: logrotate.conf.j2

- name: configure system settings, file descriptors and number of threads for kafka
  pam_limits:
    domain: "{{ specification.user }}"
    limit_type: "{{ item.limit_type }}"
    limit_item: "{{ item.limit_item }}"
    value: "{{item.value}}"
  with_items:
    - { limit_type: '-', limit_item: 'nofile', value: 128000 }
    - { limit_type: '-', limit_item: 'nproc', value: 128000 }
    - { limit_type: 'soft', limit_item: 'memlock', value: unlimited }
    - { limit_type: 'hard', limit_item: 'memlock', value: unlimited }

- name: reload settings from all system configuration files
  shell: sysctl --system

# SASL Setup
# - name: copy SASL config file
#   template: src=kafka_server_jaas.conf.j2 dest={{kafka_var.conf_dir}}/kafka_server_jaas.conf owner={{kafka_var.user}} group={{kafka_var.group}} mode=640
#   when: kafka_sasl_enabled
